{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxuYUrcbIhp2Y7f/SoHi/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisagon/collab_python/blob/master/Directives_de_base_du_prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lignes directrices pour les messages-guides\n",
        "Dans cette leçon, vous mettrez en pratique deux principes de guidage et leurs tactiques connexes afin de rédiger des messages-guides efficaces pour les grands modèles de langue.\n",
        "> Nous allons traduire *prompting* par *guidage* puisqu'il s'agit de guider l'I.A. dans ce que nous lui demandons et *prompt* par *message-guide*. \n",
        "\n",
        "## Configuration\n",
        "#### Chargez la clé API et les bibliothèques Python appropriées."
      ],
      "metadata": {
        "id": "azD3zvaQa-zs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce cours, nous avons fourni du code qui charge la clé API OpenAI pour vous."
      ],
      "metadata": {
        "id": "MBBAjwbtbHYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TitU3zfmgG-8",
        "outputId": "8d93f384-2b63-42b3-ff93-0c79f68887b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pGSRgCcipi3",
        "outputId": "57f69c03-f885-4ac6-c586-4f6ea18b533e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = 'sk-nCBFfyMTFpnWcX0uxxxxxxxxxdJsGRdVqn2mX9exxx9'\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "# openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "nE1a5WP0bO7J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### fonction d'aide\n",
        "Tout au long de ce cours, nous utiliserons le modèle `gpt-3.5-turbo` d'OpenAI et le [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n",
        "\n",
        "Cette fonction d'aide `get_completion` facilitera l'utilisation des invites et l'examen des résultats générés :"
      ],
      "metadata": {
        "id": "wsv_nbiZbSsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # c'est le degré d'aléa de la sortie du modèle\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "T4PIZTvRbXhQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Principes de guidage\n",
        "- Principe 1 : Rédiger des instructions claires et précises**.\n",
        "- Principe 2 : Donnez au modèle le temps de \"réfléchir \"**.\n",
        "\n",
        "### Tactiques\n",
        "\n",
        "#### Tactique 1 : Utilisez des délimiteurs pour indiquer clairement les parties distinctes de l'entrée.\n",
        "- Les délimiteurs peuvent être n'importe quoi comme : ```, \"\"\", < >, `<tag> </tag>`, `:`"
      ],
      "metadata": {
        "id": "AVIJzpeQbcwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "Vous devez exprimer ce que vous attendez d'un modèle en \\ \n",
        "fournissant des instructions aussi claires et spécifiques que possible. \\ \n",
        "Cela guidera le modèle vers le résultat souhaité, \\\n",
        "et réduira les risques de recevoir des informations non pertinentes ou incorrectes. Ne confondez pas la rédaction d'une \\\n",
        " invite claire avec la rédaction d'une invite courte. \\ \n",
        "Dans de nombreux cas, les invites plus longues offrent plus de clarté \\ \n",
        "et de contexte pour le modèle, ce qui peut conduire à une meilleure compréhension \\\n",
        "de la part du modèle et réduire les risques de recevoir des réponses non pertinentes \\ ou incorrectes, et \\\n",
        "des résultats plus détaillés et plus pertinents. \n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Résumez le texte délimité par des triples crochets \\\n",
        "en une seule phrase.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwW8En4-ddc-",
        "outputId": "841aa806-59ce-4ebc-ccc3-ef1b928515db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pour obtenir des résultats pertinents et éviter les informations incorrectes, il est important de fournir des instructions claires et spécifiques aux modèles, même si cela signifie des invites plus longues pour offrir plus de contexte.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tactique 2 : demander un résultat structuré\n",
        "- JSON, HTML"
      ],
      "metadata": {
        "id": "c4hRpROAjXm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Créez une liste de trois titres de livres inventés \\\n",
        "avec leurs auteurs et leurs genres. \n",
        "Fournissez-les au format JSON avec les clés suivantes : \n",
        "book_id, title, author, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMEw2Ql4ji3b",
        "outputId": "a17da4ef-1641-4424-8e3c-c0388b14582a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"book_id\": 1,\n",
            "    \"title\": \"Le Secret de la Forêt\",\n",
            "    \"author\": \"Marie Dupont\",\n",
            "    \"genre\": \"Fantasy\"\n",
            "},\n",
            "{\n",
            "    \"book_id\": 2,\n",
            "    \"title\": \"Le Mystère de la Maison Hantée\",\n",
            "    \"author\": \"Jeanne Martin\",\n",
            "    \"genre\": \"Thriller\"\n",
            "},\n",
            "{\n",
            "    \"book_id\": 3,\n",
            "    \"title\": \"L'Amour en Temps de Guerre\",\n",
            "    \"author\": \"Lucie Dubois\",\n",
            "    \"genre\": \"Romance Historique\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tactique 3 : Demander au modèle de vérifier si les conditions sont remplies"
      ],
      "metadata": {
        "id": "mrDJBWXajydG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texte_1 = f\"\"\"\n",
        "Préparer une tasse de thé, c'est facile ! Tout d'abord, il faut faire bouillir de l'eau. \n",
        "de l'eau bouillante. Pendant ce temps, \\\n",
        "prends une tasse et mets-y un sachet de thé. Une fois que l'eau est \\\n",
        "suffisamment chaude, verse-la sur le sachet de thé. \\ \n",
        "Laisse reposer un peu pour que le thé puisse infuser. Au bout de quelques minutes, retirez le sachet de thé. \n",
        "quelques minutes, retirez le sachet de thé. \n",
        "Si vous le souhaitez, vous pouvez ajouter du sucre ou du lait. \\ \n",
        "Et le tour est joué ! Vous avez une délicieuse \\\n",
        "tasse de thé à déguster. \n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Vous obtenez un texte délimité par des guillemets triples. \n",
        "S'il contient une séquence d'instructions, \\\n",
        "réécrivez ces instructions dans le format suivant :\n",
        "\n",
        "Étape 1 - ...\n",
        "Étape 2 - ...\n",
        "...\n",
        "Étape N - ...\n",
        "\n",
        "Si le texte ne contient pas de séquence d'instructions,\\\n",
        "il suffit alors d'écrire \\\"Aucune étape n'est fournie\\\".\n",
        "\n",
        "\\\"\\\"\\\"{texte_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Complétion pour le texte 1 :\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "5lOg6zAnk2Mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a3d778-e92a-4c94-e85d-ccf03af70037"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complétion pour le texte 1 :\n",
            "Étape 1 - Faire bouillir de l'eau.\n",
            "Étape 2 - Prendre une tasse et y mettre un sachet de thé.\n",
            "Étape 3 - Verser l'eau bouillante sur le sachet de thé.\n",
            "Étape 4 - Laisser infuser le thé pendant quelques minutes.\n",
            "Étape 5 - Retirer le sachet de thé.\n",
            "Étape 6 - Ajouter du sucre ou du lait (facultatif).\n",
            "Étape 7 - Déguster votre délicieuse tasse de thé.\n",
            "\n",
            "Note : Ce texte contient une séquence d'instructions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texte_2 = f\"\"\"\n",
        "Le soleil brille aujourd'hui et les oiseaux chantent.\n",
        "chantent. C'est une belle journée pour faire une \\\n",
        "promenade dans le parc. \n",
        "Les fleurs s'épanouissent et les \\\n",
        "arbres se balancent doucement dans la brise. Les gens \\\n",
        "sont dehors et profitent du beau temps. \\ \n",
        "Certains pique-niquent, d'autres jouent \\\n",
        "à des jeux ou se détendent simplement sur l'herbe. C'est une \\\n",
        "journée parfaite pour passer du temps à l'extérieur et apprécier la \\\n",
        "beauté de la nature. \n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Vous recevrez un texte délimité par des guillemets triples. \n",
        "S'il contient une séquence d'instructions, \\\n",
        "réécrivez ces instructions dans le format suivant :\n",
        "\n",
        "Étape 1 - ...\n",
        "Étape 2 - ...\n",
        "...\n",
        "Étape N - ...\n",
        "\n",
        "Si le texte ne contient pas de séquence d'instructions,  \n",
        "il suffit alors d'écrire \\\"Aucune étape n'est fournie\\\".\n",
        "\n",
        "\\\"\\\"\\\"{texte_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Complétion pour le texte 2 :\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "SIuzKWDPltpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca23415-d4c1-46e9-d326-53e57a2f9451"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complétion pour le texte 2 :\n",
            "Aucune étape n'est fournie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tactique 4 : guidage \"à quelques coups\".\n"
      ],
      "metadata": {
        "id": "riIUTue-l3oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invite = f\"\"\"\n",
        "Votre tâche consiste à répondre dans un style cohérent.\n",
        "\n",
        "<enfant> : Apprenez-moi la patience.\n",
        "\n",
        "<grandparent> : La rivière qui creuse la vallée la plus profonde \\\n",
        "est née d'une source modeste; la \\\n",
        "symphonie la plus grandiose naît d'une seule note ; \\\n",
        "la tapisserie la plus complexe commence par un fil solitaire.\n",
        "\n",
        "<Enfant> : Apprenez-moi ce qu'est la résilience.\n",
        "\"\"\"\n",
        "response = get_completion(invite)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "6k-H5G16l8pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90342849-4824-42a2-8a8e-a69205da5975"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Grandparent> : La résilience est la capacité de faire face aux défis et aux difficultés de la vie, de rebondir après des épreuves et de continuer à avancer malgré les obstacles. C'est comme un arbre qui plie sous le vent mais qui ne se brise pas, ou comme une fleur qui pousse à travers les fissures du béton. La résilience est une qualité précieuse qui peut être cultivée en faisant preuve de courage, de persévérance et de confiance en soi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Principe 2 : Donner au modèle le temps de \"penser\" \n",
        "\n",
        "#### Tactique 1 : Spécifier les étapes nécessaires à la réalisation d'une tâche"
      ],
      "metadata": {
        "id": "sNeN7HWkmZO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "Dans un charmant village, les frères et sœurs Jack et Jill partent \\\n",
        "dans une quête pour aller chercher de l'eau dans un \\\n",
        "puits situé au sommet d'une colline. \n",
        "Alors qu'ils grimpent en chantant joyeusement, le malheur \\\n",
        "frappe - Jack trébuche sur une pierre et tombe en bas \\\n",
        "de la colline, suivi par Jill. \\ \n",
        "Bien que légèrement blessés, les deux hommes rentrent à la maison et \\\n",
        "se retrouvent dans des étreintes réconfortantes. \n",
        "Malgré cette mésaventure, \\\n",
        "leur esprit d'aventure est resté intact. \\\n",
        "et ils ont continué à explorer avec plaisir.\n",
        "\"\"\"\n",
        "# exemple 1\n",
        "prompt_1 = f\"\"\"\n",
        "Effectuez les actions suivantes : \n",
        "1 - Résumez en 1 phrase le texte suivant délimité par des triples \\N\n",
        "avec 1 phrase.\n",
        "2 - Traduire le résumé en anglais.\n",
        "3 - Lister chaque nom dans le résumé en anglais.\n",
        "4 - Produire un objet json contenant les éléments suivants\n",
        "clés : english_summary, num_names.\n",
        "\n",
        "Séparez vos réponses par des sauts de ligne.\n",
        "\n",
        "Le texte :\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt_1)\n",
        "print(\"\\nRéponse à l'invite 1 :\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "pGHdBtQlmj_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Demande de sortie dans un format spécifié"
      ],
      "metadata": {
        "id": "VvkUQ1V6nzQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Votre tâche consiste à effectuer les actions suivantes : \n",
        "1 - Résumez le texte suivant délimité par \n",
        "  <> en 1 phrase.\n",
        "2 - Traduisez le résumé en français.\n",
        "3 - Lister chaque nom dans le résumé en français.\n",
        "4 - Produire un objet json contenant les clés suivantes \n",
        "  clés suivantes : french_summary, num_names.\n",
        "\n",
        "Utilisez le format suivant :\n",
        "Texte : <texte à résumer>\n",
        "Résumé : <résumé>\n",
        "Traduction : <summary translation>\n",
        "Noms : <liste de noms dans le résumé italien>\n",
        "JSON de sortie : <json avec résumé et num_names>\n",
        "\n",
        "Texte : <{texte}>\n",
        "\"\"\"\n",
        "response = get_completion(prompt_2)\n",
        "print(\"\\NComplétion pour l'invite 2 :\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "LqHZWpbYn6Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tactique 2 : Demander au modèle d'élaborer sa propre solution avant de se précipiter sur une conclusion."
      ],
      "metadata": {
        "id": "HBFh9ogI0uTt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIQlPZgh1OSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
