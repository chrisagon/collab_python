{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlHtIWyXvz80UhCrtaCzw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisagon/collab_python/blob/master/Transformer_un_texte.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer\n",
        "\n",
        "Dans ce carnet, nous allons explorer comment utiliser les Grands Modèles de Langage pour des tâches de transformation de texte telles que la traduction, la vérification de l'orthographe et de la grammaire, l'ajustement du ton et la conversion de format.\n",
        "\n",
        "## Configuration"
      ],
      "metadata": {
        "id": "UuHvYpLk3KTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "7mw8VRpr3PuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_BssF2f2822"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0): \n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, \n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traduction\n",
        "\n",
        "ChatGPT est entraîné avec des sources dans de nombreuses langues. Cela donne au modèle la capacité de faire de la traduction. Voici quelques exemples d'utilisation de cette capacité."
      ],
      "metadata": {
        "id": "9RGCuWHC3Z-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Traduisez le texte anglais suivant en espagnol: \\ \n",
        "```Hi, I would like to order a blender```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "MLQJKwXj3bB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is: \n",
        "```Combien coûte le lampadaire?```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "_xcw-37A3nRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following  text to French and Spanish\n",
        "and English pirate: \\\n",
        "```I want to order a basketball```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "L39SjB2G3qes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Traduisez le texte suivant en espagnol aux formes formelle et informelle : \n",
        "'Voulez-vous commander un oreiller ?'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "AhRxKlni34I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traducteur universel\n",
        "Imaginez que vous êtes responsable des technologies de l'information dans une grande entreprise multinationale de commerce électronique. Les utilisateurs vous envoient des messages dans leur langue maternelle pour vous faire part de leurs problèmes informatiques. Vos collaborateurs viennent du monde entier et ne parlent que leur langue maternelle. Vous avez besoin d'un traducteur universel !"
      ],
      "metadata": {
        "id": "eYomX3Ns4S5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_messages = [\n",
        "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal         \n",
        "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
        "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
        "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
        "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
        "] "
      ],
      "metadata": {
        "id": "7rUv9QsI4VLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for issue in user_messages:\n",
        "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
        "    lang = get_completion(prompt)\n",
        "    print(f\"Original message ({lang}): {issue}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Translate the following  text to English \\\n",
        "    and Korean: ```{issue}```\n",
        "    \"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response, \"\\n\")"
      ],
      "metadata": {
        "id": "ojXjACOP4cYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Essayez vous-même !\n",
        "Essayez quelques traductions par vous-même !"
      ],
      "metadata": {
        "id": "8bt3uWnZ4pAx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c86x7chN4t0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformation du ton\n",
        "L'écriture peut varier en fonction du public visé. ChatGPT peut produire différents tons.\n"
      ],
      "metadata": {
        "id": "JzXK99WF4uea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Traduisez ce qui suit de l'argot à une lettre d'affaires : \n",
        "\"Mec, c'est Joe, regarde les spécifications de cette lampe sur pied\".\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "zNjDBJWM46Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion de format\n",
        "ChatGPT peut convertir des formats. Le prompt doit décrire les formats d'entrée et de sortie."
      ],
      "metadata": {
        "id": "32KA1sGC5Ags"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_json = { \"resturant employees\" :[ \n",
        "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
        "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
        "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary from JSON to an HTML \\\n",
        "table with column headers and title: {data_json}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "LLwDdz115Fau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
        "display(HTML(response))"
      ],
      "metadata": {
        "id": "CPGzfSw75N66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vérification de l'orthographe et de la grammaire.\n",
        "\n",
        "Voici quelques exemples de problèmes de grammaire et d'orthographe courants et la réponse du LLM. \n",
        "\n",
        "Pour signaler au LLM que vous souhaitez qu'il relise votre texte, vous demandez au modèle de \"relire\" ou de \"relire et corriger\"."
      ],
      "metadata": {
        "id": "SKbIpG5w5Q3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [ \n",
        "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
        "  \"Yolanda has her notebook.\", # ok\n",
        "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
        "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
        "  \"Your going to need you’re notebook.\",  # Homonyms\n",
        "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
        "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
        "]\n",
        "for t in text:\n",
        "    prompt = f\"\"\"Relisez et corrigez le texte suivant\n",
        "    et réécrivez la version corrigée. Si vous ne trouvez pas\n",
        "    et des erreurs, dites simplement \"Aucune erreur trouvée\". N'utilisez pas \n",
        "    aucune ponctuation autour du texte :\n",
        "    ```{t}```\"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "j8MvsVDO5cz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "Got this for my daughter for her birthday cuz she keeps taking \\\n",
        "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
        "it everywhere with her, and it's super soft and cute.  One of the \\\n",
        "ears is a bit lower than the other, and I don't think that was \\\n",
        "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
        "though. I think there might be other options that are bigger for \\\n",
        "the same price.  It arrived a day earlier than expected, so I got \\\n",
        "to play with it myself before I gave it to my daughter.\n",
        "\"\"\"\n",
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "DCZhoEq-5v1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from redlines import Redlines\n",
        "\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ],
      "metadata": {
        "id": "bgizQ9ZC5_XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "relisez et corrigez ce commentaire. Rendez-le plus convaincant. \n",
        "Assurez-vous qu'il respecte le guide de style APA et qu'il s'adresse à un lecteur avancé. \n",
        "Produisez le document au format markdown.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "id": "5faQU7wX6Iew"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}